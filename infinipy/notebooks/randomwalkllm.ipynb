{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame-ce 2.4.1 (SDL 2.28.5, Python 3.12.1)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (agents.py, line 5)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.pyenv/versions/3.12.1/envs/abstractions/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 8\u001b[0;36m\n\u001b[0;31m    from infinipy.agents import  AgentGoal, FakeLLM, LLMAgent, CharacterAgent, RunMetadata, system_prompt, action_generation_prompt,OutlinesActionPayload, OutlinesEgoActionPayload\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/Dev/Abstractions/abstractions/goap/agents.py:5\u001b[0;36m\u001b[0m\n\u001b[0;31m    from infinipy.spatial import GridMap, Node, GameEntity, ActionResult, ActionsPayload, SummarizedActionPayload, SummarizedEgoActionPayload,\u001b[0m\n\u001b[0m                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "from infinipy.entity import Statement\n",
    "from infinipy.spatial import GridMap, Node, GameEntity, ActionResult,ActionsPayload, SummarizedActionPayload,SummarizedEgoActionPayload\n",
    "from infinipy.interactions import Move, Pickup, Drop, Open, Close, Unlock, Lock\n",
    "from infinipy.game.main import generate_dungeon\n",
    "from infinipy.agents import  AgentGoal, FakeLLM, LLMAgent, CharacterAgent, RunMetadata, system_prompt, action_generation_prompt,OutlinesActionPayload, OutlinesEgoActionPayload\n",
    "import outlines\n",
    "from outlines import models, generate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/tommasofurlanello/Documents/Dev/models/NousResearch/Hermes-2-Pro-Mistral-7B-GGUF/Hermes-2-Pro-Mistral-7B.Q8_0.gguf\"\n",
    "model_path= \"/Users/tommasofurlanello/Documents/Dev/models/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF/Nous-Hermes-2-Mixtral-8x7B-DPO.Q8_0.gguf\"\n",
    "# model_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# model = models.llamacpp(model_path, model_kwargs={\"seed\": 1337, \"n_ctx\": 8000,\"n_gpu_layers\":-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 995 tensors from /Users/tommasofurlanello/Documents/Dev/models/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF/Nous-Hermes-2-Mixtral-8x7B-DPO.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = emozilla\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                         llama.expert_count u32              = 8\n",
      "llama_model_loader: - kv  11:                    llama.expert_used_count u32              = 2\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {% for message in messages %}{{'<|im_...\n",
      "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:   32 tensors\n",
      "llama_model_loader: - type q8_0:  898 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 8\n",
      "llm_load_print_meta: n_expert_used    = 2\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 46.70 B\n",
      "llm_load_print_meta: model size       = 46.22 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = emozilla\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.96 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size = 47191.84 MiB, (47191.92 / 98304.00)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   132.82 MiB\n",
      "llm_load_tensors:      Metal buffer size = 47191.84 MiB\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating block attributes... for door\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 30016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M3 Max\n",
      "ggml_metal_init: picking default device: Apple M3 Max\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M3 Max\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 103079.22 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  3752.00 MiB, (50949.80 / 98304.00)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  3752.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 3752.00 MiB, K (f16): 1876.00 MiB, V (f16): 1876.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1986.67 MiB, (52936.47 / 98304.00)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  1986.66 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    66.63 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1638\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.expert_used_count': '2', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '7', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.expert_count': '8', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'emozilla'}\n",
      "Guessed chat format: chatml\n"
     ]
    }
   ],
   "source": [
    "def source_node_at_bottom_left_corner(source: Node, target: Optional[Node] = None) -> bool:\n",
    "    \"\"\" Check if the source node is at position bottom left of the mpa\"\"\"\n",
    "    print(\"Checking if source node at 0, 0\", source.position)\n",
    "    if source.node.position.value == (0, 0):\n",
    "        print(\"Source node at 0, 0\", source.node.position)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Create the grid map and generate the dungeon\n",
    "grid_map = GridMap(width=10, height=10)\n",
    "grid_map.register_actions([Move, Pickup, Drop, Open, Close, Unlock, Lock])\n",
    "room_width, room_height = 6, 6\n",
    "character, door, key, treasure = generate_dungeon(grid_map, room_width, room_height)\n",
    "\n",
    "# Generate the entity type map\n",
    "grid_map.generate_entity_type_map()\n",
    "\n",
    "# Create the LLMAgent\n",
    "agent = LLMAgent(grid_map, character.id, model_path, use_egocentric=True,memory_length=10)\n",
    "\n",
    "# Create the CharacterAgent with the LLMAgent\n",
    "character_agent = CharacterAgent(grid_map, agent)\n",
    "\n",
    "# Set the agent's metadata\n",
    "metadata = RunMetadata(character_id=character.id, run_number=1)\n",
    "character_agent.set_metadata(metadata)\n",
    "\n",
    "# Set the agent's goals\n",
    "goal_statement = Statement(callables=[source_node_at_bottom_left_corner])  # Example goal: reach position (0, 0)\n",
    "goal = AgentGoal(statement=goal_statement, priority=1)\n",
    "character_agent.set_goals([goal])\n",
    "\n",
    "# Get the initial observation\n",
    "initial_observation = character_agent.get_current_observation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step: 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    85 runs   (    0.09 ms per token, 11201.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22158.36 ms /  3405 tokens (    6.51 ms per token,   153.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4628.06 ms /    84 runs   (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:       total time =   26948.54 ms /  3489 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =      11.69 ms /    95 runs   (    0.12 ms per token,  8125.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24435.88 ms /  4162 tokens (    5.87 ms per token,   170.32 tokens per second)\n",
      "llama_print_timings:        eval time =    5217.10 ms /    94 runs   (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:       total time =   29895.58 ms /  4256 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Pickup' target_entity_type='Floor' target_entity_position=[5, 1] explanation_of_my_behavior='I want to pick up any items that may be on the floor near my current position. This will allow me to potentially use them later or clear the space for easier movement.'\n",
      "Generated Action: action_name='Pickup' target_entity_type='Floor' target_entity_position=[5, 1] explanation_of_my_behavior='I want to pick up any items that may be on the floor near my current position. This will allow me to potentially use them later or clear the space for easier movement.'\n",
      "Payload detected action_name='Pickup' target_entity_type='Floor' target_entity_position=[5, 1] explanation_of_my_behavior='I want to pick up any items that may be on the floor near my current position. This will allow me to potentially use them later or clear the space for easier movement.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Pickup' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='Floor' target_entity_position=(5, 1) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to pick up any items that may be on the floor near my current position. This will allow me to potentially use them later or clear the space for easier movement.'\n",
      "Conversion results: actions=[ActionInstance(source_id='1a5ccf3a-2a51-440d-b488-13c3b4c0ca72', target_id='6dbe438c-4b7b-4548-b319-c7f9697bcccb', action=Pickup(name='Pickup', prerequisites=Prerequisites(source_statements=[Statement(name='Statement', id='83703a7c-97ce-4a25-8e31-98d0624c9783', conditions={'can_act': True}, comparisons={}, callables=[])], target_statements=[Statement(name='Statement', id='8c57c9dd-7b67-47f9-ab5e-d9d419d5ac50', conditions={'is_pickupable': True}, comparisons={}, callables=[])], source_target_statements=[Statement(name='Statement', id='4486fece-2e45-4c73-bc08-3cc49957e89e', conditions={}, comparisons={'source_position': ('node', 'node', <function source_node_comparison at 0x1099d6c00>)}, callables=[])]), consequences=Consequences(source_transformations={'inventory': <function add_to_inventory at 0x1099d7060>}, target_transformations={'stored_in': <function set_stored_in at 0x1087ebba0>, 'node': None})))]\n",
      "Applying 1 actions\n",
      "Error: Action execution failed, Failed Prerequisites: [[]]\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    85 runs   (    0.10 ms per token,  9734.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26468.22 ms /  4927 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4991.30 ms /    84 runs   (   59.42 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:       total time =   31655.04 ms /  5011 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    85 runs   (    0.09 ms per token, 10879.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34723.43 ms /  5685 tokens (    6.11 ms per token,   163.72 tokens per second)\n",
      "llama_print_timings:        eval time =    5578.83 ms /    84 runs   (   66.41 ms per token,    15.06 tokens per second)\n",
      "llama_print_timings:       total time =   40486.19 ms /  5769 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    84 runs   (    0.12 ms per token,  8557.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   43692.76 ms /  6443 tokens (    6.78 ms per token,   147.46 tokens per second)\n",
      "llama_print_timings:        eval time =    5375.72 ms /    83 runs   (   64.77 ms per token,    15.44 tokens per second)\n",
      "llama_print_timings:       total time =   49294.48 ms /  6526 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    85 runs   (    0.12 ms per token,  8307.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   49680.74 ms /  7201 tokens (    6.90 ms per token,   144.95 tokens per second)\n",
      "llama_print_timings:        eval time =    5666.85 ms /    84 runs   (   67.46 ms per token,    14.82 tokens per second)\n",
      "llama_print_timings:       total time =   55582.85 ms /  7285 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    85 runs   (    0.13 ms per token,  7691.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58027.99 ms /  7959 tokens (    7.29 ms per token,   137.16 tokens per second)\n",
      "llama_print_timings:        eval time =    7618.36 ms /    84 runs   (   90.69 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =   65914.70 ms /  8043 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    6564.73 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    85 runs   (    0.12 ms per token,  8286.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   92341.18 ms /  8717 tokens (   10.59 ms per token,    94.40 tokens per second)\n",
      "llama_print_timings:        eval time =   17532.45 ms /    84 runs   (  208.72 ms per token,     4.79 tokens per second)\n",
      "llama_print_timings:       total time =  110131.25 ms /  8801 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Generated Action: action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Payload detected action_name='Move' target_entity_type='' target_entity_position=[5, 2] explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Converting to summarized from outlines\n",
      "Converting summarized payload action_name='Move' source_entity_type='Character' source_entity_position=(5, 1) source_entity_id=None source_entity_name=None source_entity_attributes={} target_entity_type='' target_entity_position=(5, 2) target_entity_id=None target_entity_name=None target_entity_attributes={} explanation_of_my_behavior='I want to move towards the door at position (5, 2) in order to attempt unlocking it or finding a way to open it.'\n",
      "Conversion results: Invalid target entity type: \n",
      "Error: Invalid target entity type: , Failed Prerequisites: None\n",
      "Checking if source node at 0, 0 name='Position' id='b094291d-c717-4b59-9bf3-cd0706fa826c' value=(5, 1)\n",
      "\n",
      "--- Step: 8 ---\n"
     ]
    }
   ],
   "source": [
    "character_agent.run(initial_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_observation = character_agent.get_current_observation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug a single step\n",
    "print(\"Initial Observation:\")\n",
    "print(initial_observation)\n",
    "\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(system_prompt(\n",
    "    grid_map.get_actions(),\n",
    "    agent.use_egocentric,\n",
    "    agent.use_outlines,\n",
    "    OutlinesEgoActionPayload,\n",
    "    OutlinesActionPayload,\n",
    "    SummarizedEgoActionPayload,\n",
    "    SummarizedActionPayload\n",
    "))\n",
    "\n",
    "print(\"\\nAction Generation Prompt:\")\n",
    "print(action_generation_prompt(\n",
    "    initial_observation,\n",
    "    character_agent.goals,\n",
    "    \"\",\n",
    "    agent.use_egocentric,\n",
    "    agent.use_outlines,\n",
    "    agent.memory_length,\n",
    "    OutlinesEgoActionPayload,\n",
    "    OutlinesActionPayload,\n",
    "    SummarizedEgoActionPayload,\n",
    "    SummarizedActionPayload\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating action...\")\n",
    "action_payload = character_agent.generate_action(initial_observation)\n",
    "print(\"Generated Action:\")\n",
    "print(action_payload)\n",
    "\n",
    "print(\"\\nExecuting action...\")\n",
    "result, error = character_agent.execute_action(action_payload)\n",
    "if error:\n",
    "    print(\"Error:\", error)\n",
    "else:\n",
    "    print(\"Action Result:\")\n",
    "    print(\"State Before:\", result[\"state_before\"])\n",
    "    print(\"State After:\", result[\"state_after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(character.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def source_node_at_00(source: Node, target: Optional[Node] = None) -> bool:\n",
    "#     print(\"Checking if source node at 0, 0\", source.position)\n",
    "#     if source.node.position.value == (0, 0):\n",
    "#         print(\"Source node at 0, 0\", source.node.position)\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "# # Create the grid map and generate the dungeon\n",
    "# grid_map = GridMap(width=10, height=10)\n",
    "# grid_map.register_actions([Move, Pickup, Drop, Open, Close, Unlock, Lock])\n",
    "# room_width, room_height = 6, 6\n",
    "# character, door, key, treasure = generate_dungeon(grid_map, room_width, room_height)\n",
    "\n",
    "# # Generate the entity type map\n",
    "# grid_map.generate_entity_type_map()\n",
    "\n",
    "# # Create the agent (either FakeLLM or LLMAgent)\n",
    "# agent = FakeLLM(grid_map, character.id, use_egocentric=True, use_outlines=True)\n",
    "# # model_path = \"./phi-2.Q4_K_M.gguf\"  # Replace with the path to your model\n",
    "# # agent = LLMAgent(grid_map, character.id, model_path)\n",
    "\n",
    "# # Create the CharacterAgent with the chosen agent\n",
    "# character_agent = CharacterAgent(grid_map, agent)\n",
    "\n",
    "# # Set the agent's metadata\n",
    "# metadata = RunMetadata(character_id=character.id, run_number=1)\n",
    "# character_agent.set_metadata(metadata)\n",
    "\n",
    "# # Set the agent's goals\n",
    "# goal_statement = Statement(callables=[source_node_at_00])  # Example goal: reach position (0, 0)\n",
    "# goal = AgentGoal(statement=goal_statement, priority=1)\n",
    "# character_agent.set_goals([goal])\n",
    "\n",
    "# # Get the initial observation\n",
    "# initial_observation = character_agent.get_current_observation()\n",
    "# # initial_observation_ego = character_agent.get_current_observation()\n",
    "\n",
    "\n",
    "\n",
    "# # Run the agent\n",
    "# character_agent.run(initial_observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_node_at_00(source: Node, target: Optional[Node] = None) -> bool:\n",
    "    print(\"Checking if source node at 0, 0\", source.position)\n",
    "    if source.node.position.value == (0, 0):\n",
    "        print(\"Source node at 0, 0\", source.node.position)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Create the grid map and generate the dungeon\n",
    "grid_map = GridMap(width=10, height=10)\n",
    "grid_map.register_actions([Move, Pickup, Drop, Open, Close, Unlock, Lock])\n",
    "room_width, room_height = 6, 6\n",
    "character, door, key, treasure = generate_dungeon(grid_map, room_width, room_height)\n",
    "\n",
    "# Generate the entity type map\n",
    "grid_map.generate_entity_type_map()\n",
    "\n",
    "# Create the LLMAgent\n",
    "agent = LLMAgent(grid_map, character.id, model_path, use_egocentric=True, use_outlines=True)\n",
    "\n",
    "# Create the CharacterAgent with the LLMAgent\n",
    "character_agent = CharacterAgent(grid_map, agent)\n",
    "\n",
    "# Set the agent's metadata\n",
    "metadata = RunMetadata(character_id=character.id, run_number=1)\n",
    "character_agent.set_metadata(metadata)\n",
    "\n",
    "# Set the agent's goals\n",
    "goal_statement = Statement(callables=[source_node_at_00])  # Example goal: reach position (0, 0)\n",
    "goal = AgentGoal(statement=goal_statement, priority=1)\n",
    "character_agent.set_goals([goal])\n",
    "\n",
    "# Get the initial observation\n",
    "initial_observation = character_agent.get_current_observation()\n",
    "\n",
    "# Debug a single step\n",
    "print(\"Initial Observation:\")\n",
    "print(initial_observation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSystem Prompt:\")\n",
    "print(system_prompt(grid_map.get_actions(), agent.use_egocentric, agent.use_outlines))\n",
    "\n",
    "print(\"\\nAction Generation Prompt:\")\n",
    "print(action_generation_prompt(initial_observation, character_agent.goals, \"\", agent.use_egocentric, agent.use_outlines, agent.memory_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating action...\")\n",
    "action_payload = character_agent.generate_action(initial_observation)\n",
    "print(\"Generated Action:\")\n",
    "print(action_payload)\n",
    "\n",
    "print(\"\\nExecuting action...\")\n",
    "result, error = character_agent.execute_action(action_payload)\n",
    "if error:\n",
    "    print(\"Error:\", error)\n",
    "else:\n",
    "    print(\"Action Result:\")\n",
    "    print(\"State Before:\", result[\"state_before\"])\n",
    "    print(\"State After:\", result[\"state_after\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug a single step\n",
    "print(\"Initial Observation:\")\n",
    "print(initial_observation)\n",
    "\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(agent.system_prompt(registered_actions=grid_map.get_actions()))\n",
    "\n",
    "print(\"\\nAction Generation Prompt:\")\n",
    "print(agent.action_generation_prompt(initial_observation, character_agent.goals, \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nGenerating action...\")\n",
    "action_payload = character_agent.generate_action(initial_observation)\n",
    "print(\"Generated Action:\")\n",
    "print(action_payload)\n",
    "\n",
    "print(\"\\nExecuting action...\")\n",
    "result, error = character_agent.execute_action(action_payload)\n",
    "if error:\n",
    "    print(\"Error:\", error)\n",
    "else:\n",
    "    print(\"Action Result:\")\n",
    "    print(\"State Before:\", result[\"state_before\"])\n",
    "    print(\"State After:\", result[\"state_after\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
